<span align="center">
    <a href="https://www.kaggle.com/"><img alt="Kaggle" src="https://img.shields.io/static/v1?label=Kaggle&message=Click&logo=Kaggle&color=20BEFF"/></a>
    <a href="https://huggingface.co/"><img src="https://img.shields.io/static/v1?label=%F0%9F%A4%97%20Hugging%20Face&message=Click&color=yellow"></a>
    <a href="https://paperswithcode.com/"><img src="https://img.shields.io/static/v1?label=%F0%9F%93%8E%20Papers%20With%20Code&message=Click&color=21cbce"></a>
    <a href="https://colab.research.google.com/github/sajjjadayobi/PersianQA/blob/main/notebooks/Demo.ipynb"><img src="https://img.shields.io/static/v1?label=Colab&message=Demo&logo=Google%20Colab&color=f9ab00"></a>
</span>

# PersianQA: a dataset for Persian Question Answering

Persian Question Answering (PersianQA) Dataset is a reading comprehension
dataset on [Persian Wikipedia](https://fa.wikipedia.org/). The crowd-sourced
dataset consists of more than 9,000 entries. Each entry can be either an
_impossible to answer_ or a question with one or more answers spanning in the
passage (the _context_) from which the questioner proposed the question.
Much like the SQuAD2.0 dataset, the impossible or _unanswerable_ questions can be
utilized to create a system which "knows that it doesn't know the answer".

On top of that, the dataset has 900 test data available.
Moreover, the first models trained on the dataset, Transformers, are available.

All the crowdworkers of the dataset are native Persian speakers. Also, it worth
mentioning that the contexts are collected from all categories of the Wiki
(Historical, Religious, Geography, Science, etc.)

At the moment, each context has 7 pairs of questions with one answer and 3
impossible questions.

As mentioned before, the dataset is inspired by the famous SQuAD2.0 dataset and is
compatible with and can be merged into it. But that's not all, the dataset here
has some relative advantages to the original SQuAD, some of which are listed below:

- Lengthier contexts
- Increased number of articles (despite having less data)
- More questions per contexts (7 comparing to 5)
- Including _informal ("Mohaaverei")_ entries
- More varied answers (names, locations, dates and more)

We train a baseline model which achieves an F1 score of 78 and an exact match ratio of 52 on [ParsiNLU dataset]()

You can check out an online [iPython Demo Notebook on Google Colab ](https://colab.research.google.com/github/sajjjadayobi/PersianQA/blob/main/notebooks/Demo.ipynb).

## Dataset Information

### Description
###  Access/Download

- You can find the data under the [`dataset/`]() directory. and use it like this
```python
import read_qa # is avalible at src/read_ds.py
train_ds = read_qa('pqa_train.json')
test_ds  = read_qa('pqa_test.json')
```
- Alternatively, you can also access the data through the HuggingFaceðŸ¤— datasets library
    - First, you need to install datasets use this command in your terminal:
```sh
pip install -q datasets
```
- Then import persian_qa dataset using load_dataset:
```python 
from datasets import load_dataset
dataset = load_dataset("SajjadAyoubi/persian_qa")
```


### Examples

| Title |         Context         |  Question  | Answer |
| :---: | :---------------------: | :--------: | :----: |
| Ø®ÙˆØ¨ØŒ Ø¨Ø¯ØŒ Ø²Ø´Øª | Ø®ÙˆØ¨ØŒ Ø¨Ø¯ØŒ Ø²Ø´Øª ÛŒÚ© ÙÛŒÙ„Ù… Ø¯Ø±Ú˜Ø§Ù†Ø± ÙˆØ³ØªØ±Ù† Ø§Ø³Ù¾Ø§Ú¯ØªÛŒ Ø­Ù…Ø§Ø³ÛŒ Ø§Ø³Øª Ú©Ù‡ ØªÙˆØ³Ø· Ø³Ø±Ø¬Ùˆ Ù„Ø¦ÙˆÙ†Ù‡ Ø¯Ø± Ø³Ø§Ù„ Û±Û¹Û¶Û¶ Ø¯Ø± Ø§ÛŒØªØ§Ù„ÛŒØ§ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯. Ø²Ø¨Ø§Ù†ÛŒ Ú©Ù‡ Ø¨Ø§Ø²ÛŒÚ¯Ø±Ø§Ù† Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ù‡ Ø¢Ù† ØªÚ©Ù„Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ù…Ø®Ù„ÙˆØ·ÛŒ Ø§Ø² Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³Øª. Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø³ÙˆÙ…ÛŒÙ† (Ùˆ Ø¢Ø®Ø±ÛŒÙ†) ÙÛŒÙ„Ù… Ø§Ø² Ø³Ù‡â€ŒÚ¯Ø§Ù†Ù‡Ù” Ø¯Ù„Ø§Ø± (Dollars Trilogy) Ø³Ø±Ø¬Ùˆ Ù„Ø¦ÙˆÙ†Ù‡ Ø§Ø³Øª. Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø± ÙÙ‡Ø±Ø³Øª Û²ÛµÛ° ÙÛŒÙ„Ù… Ø¨Ø±ØªØ± ØªØ§Ø±ÛŒØ® Ø³ÛŒÙ†Ù…Ø§ Ø¯Ø± ÙˆØ¨â€ŒÚ¯Ø§Ù‡ IMDB Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Û¸Ù«Û¸ Ø§Ø² Û±Û°ØŒ Ø±ØªØ¨Ù‡Ù” Ù‡Ø´ØªÙ… Ø±Ø§ Ø¨Ù‡ Ø®ÙˆØ¯ Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø¯Ù‡â€ŒØ§Ø³Øª Ùˆ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¨Ù‡ØªØ±ÛŒÙ† ÙÛŒÙ„Ù… ÙˆØ³ØªØ±Ù† ØªØ§Ø±ÛŒØ® Ø³ÛŒÙ†Ù…Ø§ÛŒ Ø¬Ù‡Ø§Ù† Ø´Ù†Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Â«Ø®ÙˆØ¨Â» (Ú©Ù„ÛŒÙ†Øª Ø§ÛŒØ³ØªÙˆÙˆØ¯ØŒ Ø¯Ø± ÙÛŒÙ„Ù…ØŒ Ø¨Ø§ Ù†Ø§Ù… Â«Ø¨Ù„ÙˆÙ†Ø¯ÛŒÂ») Ùˆ Â«Ø²Ø´ØªÂ» (Ø§ÛŒÙ„Ø§ÛŒ ÙˆØ§Ù„Ø§Ú©ØŒ Ø¯Ø± ÙÛŒÙ„Ù…ØŒ Ø¨Ø§ Ù†Ø§Ù… Â«ØªÙˆÚ©ÙˆÂ») Ø¨Ø§ Ù‡Ù… Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ Ø¨Ø§ Ø´Ú¯Ø±Ø¯ Ø®Ø§ØµÛŒØŒ Ø¨Ù‡ Ú¯ÙˆÙ„ Ø²Ø¯Ù† Ú©Ù„Ø§Ù†ØªØ±Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø·Ù‚ Ù…Ø®ØªÙ„Ù Ùˆ Ù¾ÙˆÙ„ Ø¯Ø±Ø¢ÙˆØ±Ø¯Ù† Ø§Ø² Ø§ÛŒÙ† Ø±Ø§Ù‡ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ù†Ø¯. Â«Ø¨Ø¯Â» (Ù„ÛŒ ÙˆØ§Ù† Ú©Ù„ÛŒÙ) Ø¢Ø¯Ù…Ú©Ø´ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡â€ŒØ®Ø§Ø·Ø± Ù¾ÙˆÙ„ Ø­Ø§Ø¶Ø± Ø¨Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù‡Ø± Ú©Ø§Ø±ÛŒ Ø§Ø³Øª. Â«Ø¨Ø¯Â»ØŒ Ú©Ù‡ Ø¯Ø± ÙÛŒÙ„Ù… Ø§Ùˆ Ø±Ø§ Â«Ø§ÙÙ†Ø¬Ù„ Ø¢ÛŒØ² (Ø§ÙÛŒÙ†Ø¬Ù„ Ø¢ÛŒØ²)Â» (Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ: Angel Eyes) ØµØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø¨Ù‡â€ŒØ¯Ù†Ø¨Ø§Ù„ Ú¯Ù†Ø¬ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø·ÛŒ Ø¬Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø¢Ù…Ø±ÛŒÚ©Ø§ØŒ Ø¨Ù‡ Ø¯Ø³Øª Ø³Ø±Ø¨Ø§Ø²ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Â«Ø¬Ú©Ø³ÙˆÙ†Â»ØŒ Ú©Ù‡ Ø¨Ø¹Ø¯Ù‡Ø§ Ø¨Ù‡ Â«Ú©Ø§Ø±Ø³ÙˆÙ†Â» Ù†Ø§Ù…Ø´ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯Ù‡ØŒ Ù…Ø®ÙÛŒ Ø´Ø¯Ù‡â€ŒØ§Ø³Øª. | Ø¯Ø± ÙÛŒÙ„Ù… Ø®ÙˆØ¨ Ø¨Ø¯ Ø²Ø´Øª Ø´Ø®ØµÛŒØª Ù‡Ø§ Ú©Ø¬Ø§ÛŒÛŒ ØµØ­Ø¨Øª Ù…ÛŒ Ú©Ù†Ù†Ø¯ØŸ |     Ù…Ø®Ù„ÙˆØ·ÛŒ Ø§Ø² Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ   |
| Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ú©Ø±Ø³Ù†Øª | Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ú©Ø±Ø³Ù†Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…Ø¹Ø§Ø¯Ù„ ÛµÛ°Û° Ù…ÛŒÙ„ÛŒÙˆÙ† ÙÙˆØª Ù…Ú©Ø¹Ø¨ØŒ Ú¯Ø§Ø² ØªØ±Ø´ Ù…ÛŒØ¯Ø§Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø³ØªØŒ Ú©Ù‡ Ø¯Ø± Ø³Ø§Ù„ Û±Û³Û¸Û± Ùˆ Ø¯Ø± Ø²Ù…Ø§Ù† ÙˆØ²Ø§Ø±Øª Ø¨ÛŒÚ˜Ù† Ù†Ø§Ù…Ø¯Ø§Ø± Ø²Ù†Ú¯Ù†Ù‡ Ø¯Ø± Ø¯ÙˆÙ„Øª Ù‡ÙØªÙ… Ù…Ø§Ø¨ÛŒÙ† Ø´Ø±Ú©Øª Ú©Ø±Ø³Ù†Øª Ù¾ØªØ±ÙˆÙ„ÛŒÙˆÙ… Ùˆ Ø´Ø±Ú©Øª Ù…Ù„ÛŒ Ù†ÙØª Ø§ÛŒØ±Ø§Ù† Ù…Ù†Ø¹Ù‚Ø¯ Ú¯Ø±Ø¯ÛŒØ¯. Ù…Ø°Ø§Ú©Ø±Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø§Ø² Ø³Ø§Ù„ Û±Û¹Û¹Û· Ø¢ØºØ§Ø² Ø´Ø¯ Ùˆ Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ø³Ø§Ù„ Û²Û°Û°Û± (Û±Û³Û¸Û±) Ø¨Ù‡ Ø§Ù…Ø¶Ø§ÛŒ Ø§ÛŒÙ† ØªÙØ§Ù‡Ù… Ù†Ø§Ù…Ù‡ Ù…Ø´ØªØ±Ú© Ø§Ù†Ø¬Ø§Ù…ÛŒØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÙØ§Ø¯ Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ØŒ Ù…Ù‚Ø±Ø± Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ Ú©Ù‡ Ø§Ø² Ø³Ø§Ù„ Û²Û°Û°Ûµ Ø¨Ø§ Ø§Ø­Ø¯Ø§Ø« Ø®Ø· Ù„ÙˆÙ„Ù‡ Ø¯Ø± Ø®Ù„ÛŒØ¬ ÙØ§Ø±Ø³ØŒ Ú¯Ø§Ø² ÙØ±Ø¢ÙˆØ±Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ù…ÛŒØ¯Ø§Ù† Ø³Ù„Ù…Ø§Ù† (Ù…Ø®Ø²Ù† Ù…Ø´ØªØ±Ú© Ø¨Ø§ Ø§Ø¨ÙˆØ¸Ø¨ÛŒ)ØŒ Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ ÛµÛ°Û° Ù…ÛŒÙ„ÛŒÙˆÙ† ÙÙˆØª Ù…Ú©Ø¹Ø¨ (Ø¨Ù‡ Ù‚ÙˆÙ„ Ø¨Ø±Ø®ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Û¶Û°Û° Ù…ÛŒÙ„ÛŒÙˆÙ† ÙÙˆØª Ù…Ú©Ø¹Ø¨) Ø¨Ù‡ Ø§Ù…Ø§Ø±Ø§Øª ØµØ§Ø¯Ø± Ø´ÙˆØ¯. Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù…Ø·Ø§Ø¨Ù‚ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¯Ø§Ø®Ù„ÛŒ Ø§ÛŒØ±Ø§Ù† Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù‡â€Œ Ùˆ ØªÙ†Ù‡Ø§ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù†ÙØªÛŒ Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª Ú©Ù‡ Ø§Ø² Ø·Ø±Ù Ù…Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ¯ØŒ ØªØ¶Ù…ÛŒÙ† Ú¯Ø±ÙØªÙ‡â€ŒØ§Ø³Øª. Ø§Ø¬Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¯Ø± Ø³Ø§Ù„ Û±Û³Û¸Û´ Ø¨Ø§ Ø¯Ù„Ø§ÛŒÙ„ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø² Ø³ÙˆÛŒ Ø¯ÛŒÙˆØ§Ù† Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø§ÛŒØ±Ø§Ù† Ø§Ø² Ø¬Ù…Ù„Ù‡ ØªØºÛŒÛŒØ± Ù†ÛŒØ§ÙØªÙ† Ø¨Ù‡Ø§ÛŒ Ú¯Ø§Ø² ØµØ§Ø¯Ø±Ø§ØªÛŒ Ùˆ Ø«Ø§Ø¨Øª Ù…Ø§Ù†Ø¯Ù† Ø¢Ù† Ø¯Ø± Ù‡ÙØª Ø³Ø§Ù„ Ø§ÙˆÙ„ Ø§Ø¬Ø±Ø§ÛŒ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù…ØªÙˆÙ‚Ù Ø´Ø¯. Ø§ÛŒÙ† Ø¯Ø± Ø­Ø§Ù„ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø·Ø¨Ù‚ ØªØ¹Ø±ÛŒÙ Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ø¯ÛŒÙˆØ§Ù† Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø§ÛŒØ±Ø§Ù†ØŒ Ø­Ù‚ Ø¯Ø®Ø§Ù„Øª Ø¯Ø± Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯Ù‡Ø§ØŒ Ù¾ÛŒØ´ Ø§Ø² Ø¢Ù†Ú©Ù‡ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯Ù‡Ø§ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ùˆ Ù…Ø§Ù„ÛŒ Ø´ÙˆÙ†Ø¯ Ø±Ø§ Ù†Ø¯Ø§Ø±Ø¯.  | Ø·Ø±ÙÛŒÙ† Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯ Ú©Ø±Ø³Ù†Øª Ú©ÛŒØ§ Ø¨ÙˆØ¯Ù†ØŸ | Ú©Ø±Ø³Ù†Øª Ù¾ØªØ±ÙˆÙ„ÛŒÙˆÙ… Ùˆ Ø´Ø±Ú©Øª Ù…Ù„ÛŒ Ù†ÙØª Ø§ÛŒØ±Ø§Ù† |
| Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡â€ŒØ³ÙˆØ±ÛŒ | Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡â€ŒØ³ÙˆØ±ÛŒ ÛŒÚ©ÛŒ Ø§Ø² Ø¬Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø§Ø² ØºØ±ÙˆØ¨ Ø¢Ø®Ø±ÛŒÙ† Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ ÛŒ Ù…Ø§Ù‡ Ø§Ø³ÙÙ†Ø¯ØŒ ØªØ§ Ù¾Ø³ Ø§Ø² Ù†ÛŒÙ…Ù‡â€ŒØ´Ø¨ ØªØ§ Ø¢Ø®Ø±ÛŒÙ† Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡ ÛŒ Ø³Ø§Ù„ØŒ Ø¨Ø±Ú¯Ø²Ø§Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø¨Ø±Ø§ÙØ±ÙˆØ®ØªÙ† Ùˆ Ù¾Ø±ÛŒØ¯Ù† Ø§Ø² Ø±ÙˆÛŒ Ø¢ØªØ´ Ù…Ø´Ø®ØµÙ‡Ù” Ø§ØµÙ„ÛŒ Ø¢Ù† Ø§Ø³Øª. Ø§ÛŒÙ† Ø¬Ø´Ù†ØŒ Ù†Ø®Ø³ØªÛŒÙ† Ø¬Ø´Ù† Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡Ù” Ø¬Ø´Ù†â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ø§Ø³Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ±ÙˆØ²ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ Ø¨Ø±Ø§ÙØ±ÙˆØ®ØªÙ† Ø¢ØªØ´ Ùˆ Ø¨Ø±Ø®ÛŒ Ø±ÙØªØ§Ø±Ù‡Ø§ÛŒ Ù†Ù…Ø§Ø¯ÛŒÙ† Ø¯ÛŒÚ¯Ø±ØŒ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¬Ù…Ø¹ÛŒ Ø¯Ø± ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø¨Ø±Ú¯Ø²Ø§Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ù‡â€ŒÚ¯ÙØªÙ‡Ù” Ø§Ø¨Ø±Ø§Ù‡ÛŒÙ… Ù¾ÙˆØ±Ø¯Ø§ÙˆÙˆØ¯ Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡â€ŒØ³ÙˆØ±ÛŒ Ø±ÛŒØ´Ù‡ Ø¯Ø± Ú¯Ø§Ù‡Ù†Ø¨Ø§Ø±Ù Ù‡ÙŽÙ…ÙŽØ³Ù’Ù¾ÙŽØªÙ’Ù…ÙŽØ¯ÙŽÙ… Ø²Ø±ØªØ´ØªÛŒØ§Ù† Ùˆ Ù†ÛŒØ² Ø¬Ø´Ù† Ù†Ø²ÙˆÙ„ ÙØ±ÙˆÙ‡Ø±Ù‡Ø§ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø´Ø´ Ø±ÙˆØ² Ù¾ÛŒØ´ Ø§Ø² ÙØ±Ø§Ø±Ø³ÛŒØ¯Ù† Ù†ÙˆØ±ÙˆØ² Ø¨Ø±Ú¯Ø²Ø§Ø± Ù…ÛŒâ€ŒØ´Ø¯. Ø§Ø­ØªÙ…Ø§Ù„ Ø¯ÛŒÚ¯Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡â€ŒØ³ÙˆØ±ÛŒ Ø¨Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ Ùˆ Ø´Ú©Ù„ ØªØ­ÙˆÙ„â€ŒÛŒØ§ÙØªÙ‡â€ŒØ§ÛŒ Ø§Ø² Ø¬Ø´Ù† Ø³Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ú©Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø¹ÛŒØ¯ÛŒ Ø§Ø³Øª. Ø¹Ù„Ø§ÙˆÙ‡ Ø¨Ø±Ø§ÙØ±ÙˆØ®ØªÙ† Ø¢ØªØ´ØŒ Ø¢ÛŒÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¯ÛŒÚ¯Ø±ÛŒ Ù†ÛŒØ² Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú¯ÙˆÙ†Ø§Ú¯ÙˆÙ† Ø§ÛŒØ±Ø§Ù† Ø¯Ø± Ø²Ù…Ø§Ù† Ø§ÛŒÙ† Ø¬Ø´Ù† Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ØŒ Ø¯Ø± ØªØ¨Ø±ÛŒØ²ØŒ Ù…Ø±Ø¯Ù… Ø¨Ù‡ Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡â€ŒØ¨Ø§Ø²Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆÙ†Ø¯ Ú©Ù‡ Ø¨Ø§ Ú†Ø±Ø§Øº Ùˆ Ø´Ù…Ø¹ØŒ Ø¨Ù‡â€ŒØ·Ø±Ø² Ø²ÛŒØ¨Ø§ÛŒÛŒ Ú†Ø±Ø§ØºØ§Ù†ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ø³Øª. Ù‡Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ ÛŒÚ© Ø¢ÛŒÙ†Ù‡ØŒ Ø¯Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ÙÙ†Ø¯ØŒ Ùˆ ÛŒÚ© Ú©ÙˆØ²Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ù„ Ù†Ùˆ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ù‡Ù…Ù‡â€ŒØ³Ø§Ù„Ù‡ Ø´Ù‡Ø±ÙˆÙ†Ø¯Ø§Ù†ÛŒ Ø§Ø² Ø§ÛŒØ±Ø§Ù† Ø¯Ø± Ø§Ø«Ø± Ø§Ù†ÙØ¬Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø§Ø®ÙˆØ´Ø§ÛŒÙ†Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÛŒÙ† Ø¬Ø´Ù†ØŒ Ú©Ø´ØªÙ‡ ÛŒØ§ Ù…ØµØ¯ÙˆÙ… Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. | Ù†Ø§Ù… Ø¬Ø´Ù† Ø§Ø®Ø±ÛŒÙ† Ø´Ù†Ø¨Ù‡ ÛŒ Ø³Ø§Ù„ Ú†ÛŒØ³ØªØŸ | No Answer |

### Statistic

| Split | # of instances | # of unanswerables | avg. question length | avg. paragraph length | avg. answer length |
| :---: | :------------: | :----------------: | :------------------: | :-------------------: | :----------------: |
| Train |     9,000      |       2,700        |         8.39         |        224.58         |        9.61        |
| Test  |      938       |        280         |         8.02         |        220.18         |        5.99        |

The lengths are on token level.

- for more about data and more example see [here](https://github.com/sajjjadayobi/PersianQA/tree/main/dataset#readme)

## Models

Currently, two models (baseline) on [HuggingFaceðŸ¤—](https://huggingface.co/SajjadAyoubi/) model hub are using the dataset.
The models are listed in the table below.

|                                          Name                                          | Params |              Training              |
| :------------------------------------------------------------------------------------: | :----: | :--------------------------------: |
| [xlm-roberta-large-fa-qa](https://huggingface.co/SajjadAyoubi/xlm-roberta-large-fa-qa) |  558M  | fine-tuned on SQuAD2.0 + PersianQA |
|         [bert-base-fa-qa](https://huggingface.co/SajjadAyoubi/bert-base-fa-qa)         |  162M  |      fine-tuned on PersianQA       |


You can try out our existing models and study examples. For more information
on the examples, visit [this page]().

**In case you have trained any model on the dataset, we'd be more than glad to
hear the details. Please, make a pull request for that regards. Simple notebook for training baseline can be found [here]()**

### How to use

All the examples are based on the Bert version but you can use other versions as well.

#### Requirements

Transformers require `transformers` and `sentencepiece`, both of which can be
installed using `pip`.

```sh
pip install transformers sentencepiece
```

#### Pipelines ðŸš€

In case you are not familiar with Transformers, you can use pipelines instead.

Note that, pipelines can't have _no answer_ for the questions.

```python
from transformers import pipeline

model_name = "SajjadAyoubi/bert-base-fa-qa"
qa_pipeline = pipeline("question-answering", model=model_name, tokenizer=model_name)

text = "Ø³Ù„Ø§Ù… Ù…Ù† Ø³Ø¬Ø§Ø¯ Ø§ÛŒÙˆØ¨ÛŒ Ù‡Ø³ØªÙ… Û²Û° Ø³Ø§Ù„Ù…Ù‡ Ùˆ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù… "
questions = ["Ø§Ø³Ù…Ù… Ú†ÛŒÙ‡ØŸ", "Ú†Ù†Ø¯ Ø³Ø§Ù„Ù…Ù‡ØŸ", "Ø¨Ù‡ Ú†ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù…ØŸ"]

for question in questions:
    print(qa_pipeline({"context": text, "question": question}))

# >>> {'score': 0.4839823544025421, 'start': 8, 'end': 18, 'answer': 'Ø³Ø¬Ø§Ø¯ Ø§ÛŒÙˆØ¨ÛŒ'}
# >>> {'score': 0.3747948706150055, 'start': 24, 'end': 32, 'answer': 'Û²Û° Ø³Ø§Ù„Ù…Ù‡'}
# >>> {'score': 0.5945395827293396, 'start': 38, 'end': 55, 'answer': 'Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ'}
```

#### Manual approach ðŸ”¥

Using the Manual approach, it is possible to have _no answer_ with even better
performance.

- PyTorch

```python
from transformers import AutoTokenizer, AutoModelForQuestionAnswering

model_name = "SajjadAyoubi/bert-base-fa-qa"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForQuestionAnswering.from_pretrained(model_name)

text = "Ø³Ù„Ø§Ù… Ù…Ù† Ø³Ø¬Ø§Ø¯ Ø§ÛŒÙˆØ¨ÛŒ Ù‡Ø³ØªÙ… Û²Û° Ø³Ø§Ù„Ù…Ù‡ Ùˆ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù… "
questions = ["Ø§Ø³Ù…Ù… Ú†ÛŒÙ‡ØŸ", "Ú†Ù†Ø¯ Ø³Ø§Ù„Ù…Ù‡ØŸ", "Ø¨Ù‡ Ú†ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù…ØŸ"]

# this class is from src/utils.py and you can read more about it
predictor = AnswerPredictor(model, tokenizer, device="cpu", n_best=10)
preds = predictor(questions, [text] * 3, batch_size=3)

for k, v in preds.items():
    print(v)
```

Produces an output such below:

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.56it/s]
{'score': 8.040637016296387, 'text': 'Ø³Ø¬Ø§Ø¯ Ø§ÛŒÙˆØ¨ÛŒ'}
{'score': 9.901972770690918, 'text': 'Û²Û°'}
{'score': 12.117212295532227, 'text': 'Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ'}
```

- TensorFlow 2.X

```python
from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering

model_name = "SajjadAyoubi/bert-base-fa-qa"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)

text = "Ø³Ù„Ø§Ù… Ù…Ù† Ø³Ø¬Ø§Ø¯ Ø§ÛŒÙˆØ¨ÛŒ Ù‡Ø³ØªÙ… Û²Û° Ø³Ø§Ù„Ù…Ù‡ Ùˆ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù… "
questions = ["Ø§Ø³Ù…Ù… Ú†ÛŒÙ‡ØŸ", "Ú†Ù†Ø¯ Ø³Ø§Ù„Ù…Ù‡ØŸ", "Ø¨Ù‡ Ú†ÛŒ Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù…ØŸ"]

# this class is from src/utils.py, you can read more about it
predictor = TFAnswerPredictor(model, tokenizer, n_best=10)
preds = predictor(questions, [text] * 3, batch_size=3)

for k, v in preds.items():
    print(v)
```

Produces an output such below:

```text
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.56it/s]
{'score': 8.040637016296387, 'text': 'Ø³Ø¬Ø§Ø¯ Ø§ÛŒÙˆØ¨ÛŒ'}
{'score': 9.901972770690918, 'text': 'Û²Û°'}
{'score': 12.117212295532227, 'text': 'Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ'}
```

Or you can access the whole demonstration using [HowToUse iPython Notebook on
Google
Colab](https://colab.research.google.com/github/sajjjadayobi/PersianQA/blob/main/notebooks/HowToUse.ipynb)

### Evaluation

To evaluate your models, you can use the provided [evaluation script](https://github.com/sajjjadayobi/PersianQA/blob/main/src/evaluation.py).

#### Results

<!-- TODO: Explain what are these metrics -->

Although, the GLEU metrics are not the best measures to evaluate the model on,
the results are as shown below.
Best baseline scores are indicated as bold

##### On [ParsiNLU](https://github.com/persiannlp/parsinlu)

- it contuns 570 question without (unanswerable questions)

|         Model         | F1 Score  | Exact Match | Params |
| :-------------------: | :-------: | :---------: | :----: |
|         Human         |   86.2%   |      -      |   -    |
| Our XLM-Roberta-Large | **78.6%** |   52.10%    |  558M  |
|     Our ParsBERT      |   62.6%   |   35.43%    |  162M  |
| ParsiNLU's mT5-small  |   28.6%   |      -      |  300M  |
|  ParsiNLU's mT5-base  |   43.0%   |      -      |  582M  |
| ParsiNLU's mT5-large  |   60.1%   |      -      |  1.2B  |
|   ParsiNLU's mT5-XL   |   65.5%   |      -      |   -    |

##### On PersianQA testset

|         Model         |  F1 Score  | Exact Match | Params |
| :-------------------: | :--------: | :---------: | :----: |
| Our XLM-Roberta-Large | **84.81%** |   70.40%    |  558M  |
|     Our ParsBERT      |   70.06%   |   53.55%    |  162M  |


## Experiment

As far as we managed to experiment with the dataset, the best results always
came from merging the dataset with other big datasets (in other languages) such
as SQuAD using multilingual models.  Foremost, try to establish the "reading
comprehension" concept in your idea with the larger dataset and then transfer
the knowledge to Persian with this very dataset.

However, this method is not only limited to this application and can be put to
use in other domains and smaller datasets.

## Contact us
If you have a technical question regarding the dataset, code or publication, please create an issue in this repository. 
This is the fastest way to reach us.
<!-- TODO: we would be happy to hear from you about better models -->

# Citation

Yet, we didn't publish any papers on the work.
However, if you did, please cite us properly with an entry like one below.

```bibtex
@misc{PersianQA,
  author          = {Ayoubi, Sajjad \& Davoodeh, Mohammad Yasin},
  title           = {PersianQA: a dataset for Persian Question Answering},
  year            = 2021,
  publisher       = {GitHub},
  journal         = {GitHub repository},
  howpublished    = {\url{https://github.com/SajjjadAyobi/PersianQA}},
}
```

## Acknowledgment
At last, the process of bringing this dataset up and providing it, much like any other work in the field, is a cumbersome and costly task.
This was but a tiny help to Persian Open-Source community and we are sincerely wishing it provides inspiration and ground work for other Free projects.

- Thanks to _Navid Kanani_ and _Abbas Ayoubi_
- Thanks to Googleâ€™s ColabðŸ˜„ and HuggingFaceðŸ¤— for making this work easier 
